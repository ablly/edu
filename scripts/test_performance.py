"""
æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢ã€ç¼“å­˜åŠŸèƒ½å’ŒAPIå“åº”æ€§èƒ½
"""

import os
import sys
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from sqlalchemy import create_engine, text
from utils.cache import cached, cache_set, cache_get, get_cache_stats, clear_cache


def get_database_url():
    """è·å–æ•°æ®åº“URL"""
    return os.getenv('DATABASE_URL', 'postgresql://edupilot_user:050102@localhost:5432/edupilot_db')


def test_database_query_performance():
    """æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½"""
    print("\n" + "="*60)
    print("    æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯•")
    print("="*60 + "\n")
    
    engine = create_engine(get_database_url())
    
    tests = [
        {
            'name': 'ç”¨æˆ·åˆ—è¡¨æŸ¥è¯¢',
            'query': 'SELECT * FROM users LIMIT 10',
            'iterations': 5
        },
        {
            'name': 'ä¼šå‘˜çŠ¶æ€æŸ¥è¯¢',
            'query': '''
                SELECT u.id, u.username, um.tier_id, um.start_date, um.end_date, um.is_active
                FROM users u
                LEFT JOIN user_memberships um ON u.id = um.user_id
                WHERE um.is_active = true
                LIMIT 10
            ''',
            'iterations': 5
        },
        {
            'name': 'æ”¯ä»˜è®¢å•æŸ¥è¯¢',
            'query': '''
                SELECT pt.*, u.username
                FROM payment_transactions pt
                JOIN users u ON pt.user_id = u.id
                ORDER BY pt.created_at DESC
                LIMIT 20
            ''',
            'iterations': 5
        },
        {
            'name': 'ä½¿ç”¨æ—¥å¿—ç»Ÿè®¡',
            'query': '''
                SELECT user_id, COUNT(*) as usage_count
                FROM usage_logs
                GROUP BY user_id
                LIMIT 10
            ''',
            'iterations': 5
        }
    ]
    
    results = []
    
    with engine.connect() as conn:
        for test in tests:
            times = []
            print(f"æµ‹è¯•: {test['name']}")
            
            for i in range(test['iterations']):
                start_time = time.time()
                try:
                    result = conn.execute(text(test['query']))
                    _ = result.fetchall()
                    end_time = time.time()
                    query_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                    times.append(query_time)
                    print(f"  è¿è¡Œ {i+1}: {query_time:.2f}ms")
                except Exception as e:
                    print(f"  è¿è¡Œ {i+1}: å¤±è´¥ - {str(e)[:50]}")
            
            if times:
                avg_time = sum(times) / len(times)
                min_time = min(times)
                max_time = max(times)
                
                results.append({
                    'name': test['name'],
                    'avg_time': avg_time,
                    'min_time': min_time,
                    'max_time': max_time
                })
                
                print(f"  å¹³å‡: {avg_time:.2f}ms | æœ€å¿«: {min_time:.2f}ms | æœ€æ…¢: {max_time:.2f}ms")
            print()
    
    return results


def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    print("\n" + "="*60)
    print("    ç¼“å­˜åŠŸèƒ½æ€§èƒ½æµ‹è¯•")
    print("="*60 + "\n")
    
    # æ¸…ç©ºç¼“å­˜
    clear_cache()
    
    # æµ‹è¯•1: åŸºç¡€ç¼“å­˜è¯»å†™
    print("æµ‹è¯•1: åŸºç¡€ç¼“å­˜è¯»å†™")
    
    # å†™å…¥æµ‹è¯•
    write_times = []
    for i in range(100):
        start = time.time()
        cache_set(f"test_key_{i}", {"data": f"value_{i}", "index": i}, ttl=300)
        write_times.append((time.time() - start) * 1000)
    
    avg_write = sum(write_times) / len(write_times)
    print(f"  å†™å…¥100ä¸ªç¼“å­˜é¡¹")
    print(f"  å¹³å‡å†™å…¥æ—¶é—´: {avg_write:.4f}ms")
    
    # è¯»å–æµ‹è¯•
    read_times = []
    for i in range(100):
        start = time.time()
        data = cache_get(f"test_key_{i}")
        read_times.append((time.time() - start) * 1000)
    
    avg_read = sum(read_times) / len(read_times)
    print(f"  è¯»å–100ä¸ªç¼“å­˜é¡¹")
    print(f"  å¹³å‡è¯»å–æ—¶é—´: {avg_read:.4f}ms")
    
    if avg_read > 0:
        print(f"  æ€§èƒ½æå‡: {avg_write/avg_read:.1f}x (ç›¸æ¯”å†™å…¥)\n")
    else:
        print(f"  æ€§èƒ½æå‡: æå¿«ï¼ˆ< 0.001msï¼‰\n")
    
    # æµ‹è¯•2: è£…é¥°å™¨ç¼“å­˜
    print("æµ‹è¯•2: è£…é¥°å™¨ç¼“å­˜æ•ˆæœ")
    
    @cached(ttl=300, key_prefix="expensive_calc")
    def expensive_calculation(n):
        """æ¨¡æ‹Ÿè€—æ—¶è®¡ç®—"""
        time.sleep(0.1)  # æ¨¡æ‹Ÿ100msçš„è®¡ç®—
        return sum(range(n))
    
    # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆæœªç¼“å­˜ï¼‰
    start = time.time()
    result1 = expensive_calculation(1000)
    time_no_cache = (time.time() - start) * 1000
    
    # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆå·²ç¼“å­˜ï¼‰
    start = time.time()
    result2 = expensive_calculation(1000)
    time_with_cache = (time.time() - start) * 1000
    
    print(f"  æ— ç¼“å­˜è°ƒç”¨: {time_no_cache:.2f}ms")
    print(f"  æœ‰ç¼“å­˜è°ƒç”¨: {time_with_cache:.2f}ms")
    
    if time_with_cache > 0:
        print(f"  æ€§èƒ½æå‡: {time_no_cache/time_with_cache:.1f}x")
        print(f"  ç¼“å­˜åŠ é€Ÿ: {((time_no_cache - time_with_cache) / time_no_cache * 100):.1f}%\n")
    else:
        print(f"  æ€§èƒ½æå‡: æå¿«ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰\n")
    
    # æµ‹è¯•3: ç¼“å­˜ç»Ÿè®¡
    stats = get_cache_stats()
    print("æµ‹è¯•3: ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯")
    print(f"  æ€»ç¼“å­˜é¡¹: {stats['total_items']}")
    print(f"  æ´»è·ƒé¡¹: {stats['active_items']}")
    print(f"  è¿‡æœŸé¡¹: {stats['expired_items']}")
    print(f"  å†…å­˜ä½¿ç”¨: {stats['memory_usage_estimate']}\n")
    
    return {
        'avg_write_time': avg_write,
        'avg_read_time': avg_read,
        'cache_speedup': time_no_cache / time_with_cache if time_with_cache > 0 else 999,
        'cache_items': stats['total_items']
    }


def test_concurrent_requests():
    """æµ‹è¯•å¹¶å‘è¯·æ±‚æ€§èƒ½ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    print("\n" + "="*60)
    print("    å¹¶å‘è¯·æ±‚æ¨¡æ‹Ÿæµ‹è¯•")
    print("="*60 + "\n")
    
    # æ¸…ç©ºç¼“å­˜é‡æ–°æµ‹è¯•
    clear_cache()
    
    @cached(ttl=300)
    def get_membership_status(user_id):
        """æ¨¡æ‹Ÿä¼šå‘˜çŠ¶æ€æŸ¥è¯¢"""
        time.sleep(0.05)  # æ¨¡æ‹Ÿ50msæ•°æ®åº“æŸ¥è¯¢
        return {
            'user_id': user_id,
            'tier': 'premium',
            'expires_at': '2025-12-31'
        }
    
    # æµ‹è¯•ç›¸åŒè¯·æ±‚ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    print("æµ‹è¯•: 100æ¬¡ç›¸åŒç”¨æˆ·IDçš„æŸ¥è¯¢")
    
    start = time.time()
    for _ in range(100):
        _ = get_membership_status(1)
    total_time_cached = (time.time() - start) * 1000
    
    print(f"  æ€»è€—æ—¶: {total_time_cached:.2f}ms")
    print(f"  å¹³å‡æ¯æ¬¡: {total_time_cached/100:.2f}ms")
    print(f"  ç¼“å­˜å‘½ä¸­ç‡: 99% (ä»…ç¬¬ä¸€æ¬¡æŸ¥è¯¢æ•°æ®åº“)\n")
    
    # æ¸…ç©ºç¼“å­˜ï¼Œæµ‹è¯•æ— ç¼“å­˜æƒ…å†µ
    clear_cache()
    get_membership_status.clear_cache()
    
    print("å¯¹æ¯”: 100æ¬¡æŸ¥è¯¢ï¼ˆæ— ç¼“å­˜ï¼‰")
    start = time.time()
    for i in range(100):
        _ = get_membership_status(i)  # ä¸åŒIDï¼Œæ¯æ¬¡éƒ½æŸ¥è¯¢
    total_time_no_cache = (time.time() - start) * 1000
    
    print(f"  æ€»è€—æ—¶: {total_time_no_cache:.2f}ms")
    print(f"  å¹³å‡æ¯æ¬¡: {total_time_no_cache/100:.2f}ms")
    
    if total_time_cached > 0:
        print(f"  æ€§èƒ½å¯¹æ¯”: ç¼“å­˜æ¯”æ— ç¼“å­˜å¿« {total_time_no_cache/total_time_cached:.1f}x\n")
    else:
        print(f"  æ€§èƒ½å¯¹æ¯”: æå¿«ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰\n")
    
    return {
        'cached_time': total_time_cached,
        'no_cache_time': total_time_no_cache,
        'speedup': total_time_no_cache / total_time_cached if total_time_cached > 0 else 999
    }


def generate_performance_report(db_results, cache_results, concurrent_results):
    """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("    æ€§èƒ½æµ‹è¯•æŠ¥å‘Šæ€»ç»“")
    print("="*60 + "\n")
    
    # æ•°æ®åº“æŸ¥è¯¢æŠ¥å‘Š
    if db_results:
        print("ğŸ“Š æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½")
        print("-" * 60)
        for result in db_results:
            print(f"\n{result['name']}:")
            print(f"  â€¢ å¹³å‡å“åº”: {result['avg_time']:.2f}ms")
            print(f"  â€¢ æœ€å¿«å“åº”: {result['min_time']:.2f}ms")
            print(f"  â€¢ æœ€æ…¢å“åº”: {result['max_time']:.2f}ms")
            
            # æ€§èƒ½è¯„çº§
            if result['avg_time'] < 20:
                rating = "ğŸŸ¢ ä¼˜ç§€"
            elif result['avg_time'] < 50:
                rating = "ğŸŸ¡ è‰¯å¥½"
            elif result['avg_time'] < 100:
                rating = "ğŸŸ  ä¸€èˆ¬"
            else:
                rating = "ğŸ”´ éœ€ä¼˜åŒ–"
            print(f"  â€¢ æ€§èƒ½è¯„çº§: {rating}")
    
    # ç¼“å­˜æ€§èƒ½æŠ¥å‘Š
    print("\n\nâš¡ ç¼“å­˜ç³»ç»Ÿæ€§èƒ½")
    print("-" * 60)
    print(f"\nåŸºç¡€æ“ä½œ:")
    print(f"  â€¢ å†™å…¥é€Ÿåº¦: {cache_results['avg_write_time']:.4f}ms")
    print(f"  â€¢ è¯»å–é€Ÿåº¦: {cache_results['avg_read_time']:.4f}ms")
    
    if cache_results['avg_read_time'] > 0:
        print(f"  â€¢ è¯»å†™æ¯”: {cache_results['avg_write_time']/cache_results['avg_read_time']:.1f}:1")
    else:
        print(f"  â€¢ è¯»å†™æ¯”: æå¿«ï¼ˆ< 0.001msï¼‰")
    
    print(f"\nè£…é¥°å™¨ç¼“å­˜:")
    print(f"  â€¢ æ€§èƒ½æå‡: {cache_results['cache_speedup']:.1f}x")
    print(f"  â€¢ ç¼“å­˜é¡¹æ•°: {cache_results['cache_items']}")
    
    # å¹¶å‘æµ‹è¯•æŠ¥å‘Š
    print("\n\nğŸš€ å¹¶å‘è¯·æ±‚æ€§èƒ½")
    print("-" * 60)
    print(f"\n100æ¬¡ç›¸åŒè¯·æ±‚:")
    print(f"  â€¢ æœ‰ç¼“å­˜: {concurrent_results['cached_time']:.2f}ms (avg: {concurrent_results['cached_time']/100:.2f}ms/æ¬¡)")
    print(f"  â€¢ æ— ç¼“å­˜: {concurrent_results['no_cache_time']:.2f}ms (avg: {concurrent_results['no_cache_time']/100:.2f}ms/æ¬¡)")
    print(f"  â€¢ æ€§èƒ½æå‡: {concurrent_results['speedup']:.1f}x")
    
    # ä¼˜åŒ–å»ºè®®
    print("\n\nğŸ’¡ ä¼˜åŒ–å»ºè®®")
    print("-" * 60)
    
    if db_results:
        slow_queries = [r for r in db_results if r['avg_time'] > 50]
        if slow_queries:
            print("\néœ€è¦ä¼˜åŒ–çš„æŸ¥è¯¢:")
            for query in slow_queries:
                print(f"  â€¢ {query['name']} (å¹³å‡ {query['avg_time']:.2f}ms)")
                print(f"    å»ºè®®: æ£€æŸ¥æ˜¯å¦æ·»åŠ äº†ç›¸åº”ç´¢å¼•")
        else:
            print("\nâœ… æ‰€æœ‰æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½è‰¯å¥½ï¼")
    
    if cache_results['cache_speedup'] < 10:
        print("\nâš ï¸  ç¼“å­˜åŠ é€Ÿæ•ˆæœè¾ƒä½ï¼Œè€ƒè™‘:")
        print("  â€¢ å¢åŠ ç¼“å­˜TTLæ—¶é—´")
        print("  â€¢ ç¼“å­˜æ›´å¤šçƒ­ç‚¹æ•°æ®")
    else:
        print("\nâœ… ç¼“å­˜ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼")
    
    print("\n\nâœ¨ æµ‹è¯•å®Œæˆï¼")
    print("="*60 + "\n")


def main():
    """ä¸»å‡½æ•°"""
    print("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘        EduPilot æ€§èƒ½æµ‹è¯•å·¥å…·                             â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"\næµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    try:
        # æµ‹è¯•1: æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
        db_results = test_database_query_performance()
        
        # æµ‹è¯•2: ç¼“å­˜åŠŸèƒ½æ€§èƒ½
        cache_results = test_cache_performance()
        
        # æµ‹è¯•3: å¹¶å‘è¯·æ±‚æ€§èƒ½
        concurrent_results = test_concurrent_requests()
        
        # ç”ŸæˆæŠ¥å‘Š
        generate_performance_report(db_results, cache_results, concurrent_results)
        
        print("ğŸ“„ æç¤ºï¼š")
        print("  â€¢ å¦‚éœ€æµ‹è¯•APIæ¥å£ï¼Œè¯·è¿è¡ŒæœåŠ¡å™¨åè®¿é—®ï¼š")
        print("    curl -w \"\\nTime: %{time_total}s\\n\" http://localhost:5000/api/membership/tiers")
        print("  â€¢ æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–è¯·è¿è¡Œï¼š")
        print("    python scripts/add_database_indexes.py")
        print("  â€¢ é™æ€èµ„æºå‹ç¼©è¯·è¿è¡Œï¼š")
        print("    python scripts/minify_assets.py\n")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

